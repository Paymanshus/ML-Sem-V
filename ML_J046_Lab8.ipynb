{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Lab8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsV4LkPvSYyHHsPjuONXZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paymanshus/ML-Sem-V/blob/master/ML_J046_Lab8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU451NuPhqwQ"
      },
      "source": [
        "#Classification of imagenet data using Neural network models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgz_Hs5fhs3Y"
      },
      "source": [
        "Objectives:\n",
        "* Download from imagenet (Atleast ->Train-60, val-20,test-20)\n",
        "* Perform data  augmentation\n",
        "* Decide the bayes optimal error for the dataset\n",
        "* Perform classification on given dataset\n",
        "* Perform error analysis\n",
        "* Select correct architecture for maximum accuracy on cross validation and test set\n",
        "* Plot accuracy vs validation acc and loss vs validation loss during epochs\n",
        "* List hyper-parameters used and callbacks\n",
        "* Layers, units, activations (settings of activations), initializers, regularizers\n",
        "* Batchnorm, dropout rate\n",
        "* Optimizer settings - learning rate, momentum\n",
        "* Metrics<br>\n",
        "Loss function\n",
        "* Train, validation and test split\n",
        "* Callbacks settings - earlystopping, modelcheckpoint, reduceLR\n",
        "* Data augmentations used - Batch size, steps per epoch, epochs\n",
        "* Dataset - \n",
        "Indian elephants, african elephants and tuskers \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FVdkHjNiOLg"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import plotly.graph_objects as go\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZQbsVb1iU6U"
      },
      "source": [
        "!mkdir /content/IndAfrTusk_train/ \n",
        "!mkdir /content/IndAfrTusk_valid/\n",
        "!mkdir /content/IndAfrTusk_test/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR1EwiPKiXfu"
      },
      "source": [
        "\n",
        "img_rows, img_cols = 240, 240\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "num_train = 210\n",
        "num_valid = 70\n",
        "num_test = 70"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psy8yzdzibLm"
      },
      "source": [
        "ind_ele = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02504013\")\n",
        "ind_ele_soup = BeautifulSoup(ind_ele.content, 'html.parser')\n",
        "ind_ele_str = str(ind_ele_soup)\n",
        "ind_ele_urls = ind_ele_str.split('\\r\\n')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVuefED_ibbB"
      },
      "source": [
        "afr_ele = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02504458\")\n",
        "afr_ele_soup = BeautifulSoup(afr_ele.content, 'html.parser')\n",
        "afr_ele_str = str(afr_ele_soup)\n",
        "afr_ele_urls = afr_ele_str.split('\\r\\n')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27SMA2vMieG2"
      },
      "source": [
        "tusker = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n01871265\")\n",
        "tusker_soup = BeautifulSoup(tusker.content, 'html.parser')\n",
        "tusker_str = str(tusker_soup)\n",
        "tusker_urls = tusker_str.split('\\r\\n')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgW2AR5nifiu"
      },
      "source": [
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "\treturn image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPglqCTHig0t",
        "outputId": "09499996-c87f-4bb2-cef1-c554fa2fbc40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for progress in tqdm(range(num_train)):\n",
        "    if not ind_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(ind_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_train/Indian.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_train)):\n",
        "    if not afr_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(afr_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_train/African.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_train)):\n",
        "    if not tusker_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(tusker_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_train/Tusker.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 210/210 [04:34<00:00,  1.31s/it]\n",
            "100%|██████████| 210/210 [02:40<00:00,  1.31it/s]\n",
            "100%|██████████| 210/210 [04:27<00:00,  1.28s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsqnN9OsiyBI",
        "outputId": "e7a59805-bd1f-4f0c-c494-e3e1ac77cead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for progress in tqdm(range(num_valid)):\n",
        "    if not ind_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(ind_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_valid/Indian.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_valid)):\n",
        "    if not afr_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(afr_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_valid/African.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_valid)):\n",
        "    if not tusker_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(tusker_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_valid/Tusker.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70/70 [01:26<00:00,  1.24s/it]\n",
            "100%|██████████| 70/70 [00:21<00:00,  3.24it/s]\n",
            "100%|██████████| 70/70 [01:39<00:00,  1.42s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW3dt9BejCXU",
        "outputId": "3a421d4f-cc9d-429a-80bf-db3c7ce060f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for progress in tqdm(range(num_test)):\n",
        "    if not ind_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(ind_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_test/Indian.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_test)):\n",
        "    if not afr_ele_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(afr_ele_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_test/African.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in tqdm(range(num_test)):\n",
        "    if not tusker_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(tusker_urls[progress])\n",
        "        if (len(I.shape))==3:\n",
        "          save_path = '/content/IndAfrTusk_test/Tusker.'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "      except:\n",
        "        None"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70/70 [01:39<00:00,  1.43s/it]\n",
            "100%|██████████| 70/70 [00:21<00:00,  3.33it/s]\n",
            "100%|██████████| 70/70 [01:37<00:00,  1.40s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKIFS1JVjESF"
      },
      "source": [
        "original_train = '/content/IndAfrTusk_train'\n",
        "original_valid = '/content/IndAfrTusk_valid'\n",
        "original_test = '/content/IndAfrTusk_test'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV4idTR3jFs4"
      },
      "source": [
        "filenames = os.listdir(original_train)\n",
        "cat_train = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Indian':\n",
        "        cat_train.append('0')\n",
        "    elif category == 'African':\n",
        "        cat_train.append('1')\n",
        "    else:\n",
        "        cat_train.append('2')\n",
        "\n",
        " \n",
        "filenames = os.listdir(original_valid)\n",
        "cat_valid = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Indian':\n",
        "        cat_valid.append('0')\n",
        "    elif category == 'African':\n",
        "        cat_valid.append('1')\n",
        "    else:\n",
        "        cat_valid.append('2')\n",
        "\n",
        "\n",
        "filenames = os.listdir(original_test)\n",
        "cat_test = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Indian':\n",
        "        cat_test.append('0')\n",
        "    elif category == 'African':\n",
        "        cat_test.append('1')\n",
        "    else:\n",
        "        cat_test.append('2')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2rKQPbCjHEa"
      },
      "source": [
        "train = pd.DataFrame({'File':os.listdir(original_train),'Label':cat_train})\n",
        "train.to_csv('IndAfrTusk_train.csv',index=False)\n",
        "\n",
        "valid = pd.DataFrame({'File':os.listdir(original_valid),'Label':cat_valid})\n",
        "valid.to_csv('IndAfrTusk_valid.csv',index=False)\n",
        "\n",
        "test = pd.DataFrame({'File':os.listdir(original_test),'Label':cat_test})\n",
        "test.to_csv('IndAfrTusk_test.csv',index=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RmiX90jJC1",
        "outputId": "f900ab85-7318-4e7f-81b4-b1a93fac3818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.shape, valid.shape, test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 2), (128, 2), (128, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdXH8f8xjLqb"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLsQk89PjN0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   zoom_range=0.1,\n",
        "                                   vertical_flip=True,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=90,\n",
        "                                   shear_range=0.1,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255.0,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   zoom_range=0.1,\n",
        "                                   vertical_flip=True,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=90,\n",
        "                                   shear_range=0.1,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVkjU6wJjQdf",
        "outputId": "45a58e6d-2fc0-456b-d1ab-ad9472d52a68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_aug = train_datagen.flow_from_dataframe(dataframe=train,\n",
        "                                              directory=original_train,\n",
        "                                              x_col='File',\n",
        "                                              y_col='Label',\n",
        "                                              target_size=(img_rows, img_cols),\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True,\n",
        "                                              seed=0,\n",
        "                                              color_mode='rgb')\n",
        "\n",
        "valid_aug = valid_datagen.flow_from_dataframe(dataframe=valid,\n",
        "                                              directory=original_valid,\n",
        "                                              x_col='File',\n",
        "                                              y_col='Label',\n",
        "                                              target_size=(img_rows, img_cols),\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True,\n",
        "                                              seed=0,\n",
        "                                              color_mode='rgb')\n",
        "\n",
        "test_aug = test_datagen.flow_from_dataframe(dataframe=test,\n",
        "                                            directory=original_test,\n",
        "                                            x_col='File',\n",
        "                                            y_col='Label',\n",
        "                                            target_size=(img_rows, img_cols),\n",
        "                                            class_mode='categorical',\n",
        "                                            shuffle=False,\n",
        "                                            color_mode='rgb')\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 404 validated image filenames belonging to 3 classes.\n",
            "Found 128 validated image filenames belonging to 3 classes.\n",
            "Found 128 validated image filenames belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEPl5Y4ijSre"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(512, kernel_size=(img_rows, img_cols), padding='valid', activation='relu',input_shape=input_shape))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=3, activation='softmax'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZCIUPzojUOr"
      },
      "source": [
        "filepath = \"weights-best.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', verbose=1, patience=3, save_best_only=True, mode='max')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, min_delta=0.001, baseline=0.9)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3, factor=0.01, min_lr=0.00001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNVr_QmCjY_K",
        "outputId": "ad3872ab-fde1-4309-8672-3670f26b3330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(train_aug, validation_data=valid_aug, epochs=10, callbacks=[checkpoint,es,reduce_lr])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0928 - accuracy: 0.3787\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.32812, saving model to weights-best.hdf5\n",
            "13/13 [==============================] - 58s 4s/step - loss: 1.0928 - accuracy: 0.3787 - val_loss: 1.1145 - val_accuracy: 0.3281\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.1031 - accuracy: 0.3639\n",
            "Epoch 00002: val_accuracy improved from 0.32812 to 0.41406, saving model to weights-best.hdf5\n",
            "13/13 [==============================] - 58s 4s/step - loss: 1.1031 - accuracy: 0.3639 - val_loss: 1.1159 - val_accuracy: 0.4141\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0962 - accuracy: 0.3886\n",
            "Epoch 00003: val_accuracy did not improve from 0.41406\n",
            "13/13 [==============================] - 57s 4s/step - loss: 1.0962 - accuracy: 0.3886 - val_loss: 1.0871 - val_accuracy: 0.3438\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67hx_Zo7jZ3G",
        "outputId": "fa4a1599-fdbb-4b2f-8e96-674a2bcb9400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(test_aug)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 182ms/step - loss: 1.0867 - accuracy: 0.3203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.086659550666809, 0.3203125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}